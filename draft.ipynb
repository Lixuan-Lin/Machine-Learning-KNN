{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from knn import KNN\n",
    "\n",
    "############################################################################\n",
    "# DO NOT MODIFY ABOVE CODES\n",
    "############################################################################\n",
    "\n",
    "\n",
    "# TODO: implement F1 score\n",
    "def f1_score(real_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    Information on F1 score - https://en.wikipedia.org/wiki/F1_score\n",
    "    :param real_labels: List[int]\n",
    "    :param predicted_labels: List[int]\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    assert len(real_labels) == len(predicted_labels)\n",
    "    \n",
    "    TP = np.sum(np.multiply(real_labels, predicted_labels))\n",
    "    FP = np.sum(np.multiply(np.logical_not(real_labels), predicted_labels))\n",
    "    TN = np.sum(np.multiply(np.logical_not(real_labels), np.logical_not(predicted_labels)))\n",
    "    FN = np.sum(np.multiply(real_labels, np.logical_not(predicted_labels)))\n",
    "    \n",
    "    if ((TP+FP)==0 or (TP+FN)==0):\n",
    "        F1 = 0\n",
    "    else:\n",
    "        Precision = TP / (TP+FP)\n",
    "        Recall = TP / (TP + FN)\n",
    "        if ((Recall+Precision)==0):\n",
    "            F1 = 0\n",
    "        else:\n",
    "            F1 = 2*Precision*Recall / (Recall+Precision)\n",
    "    \n",
    "    return F1  \n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "class Distances:\n",
    "    @staticmethod\n",
    "    # TODO\n",
    "    def canberra_distance(point1, point2):\n",
    "        quotient = np.abs(np.asarray(point1)-np.asarray(point2))/(np.abs(np.asarray(point1))+np.abs(np.asarray(point2)))\n",
    "        cd = np.sum(quotient)\n",
    "        return cd\n",
    "        \"\"\"\n",
    "        :param point1: List[float]\n",
    "        :param point2: List[float]\n",
    "        :return: float\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @staticmethod\n",
    "    # TODO\n",
    "    def minkowski_distance(point1, point2):\n",
    "        power = np.float_power(np.abs(np.asarray(point1)-np.asarray(point2)), 3)\n",
    "        total = np.sum(power)\n",
    "        md = total ** (1/3)\n",
    "        return md\n",
    "        \"\"\"\n",
    "        Minkowski distance is the generalized version of Euclidean Distance\n",
    "        It is also know as L-p norm (where p>=1) that you have studied in class\n",
    "        For our assignment we need to take p=3\n",
    "        Information on Minkowski distance - https://en.wikipedia.org/wiki/Minkowski_distance\n",
    "        :param point1: List[float]\n",
    "        :param point2: List[float]\n",
    "        :return: float\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @staticmethod\n",
    "    # TODO\n",
    "    def euclidean_distance(point1, point2):\n",
    "        sub = np.subtract(point1, point2)\n",
    "        dot = np.dot(sub, sub)\n",
    "        ed = np.sqrt(dot)\n",
    "        return ed\n",
    "        \"\"\"\n",
    "        :param point1: List[float]\n",
    "        :param point2: List[float]\n",
    "        :return: float\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @staticmethod\n",
    "    # TODO\n",
    "    def inner_product_distance(point1, point2):\n",
    "        ipd=np.dot(point1, point2)\n",
    "        return ipd\n",
    "        \"\"\"\n",
    "        :param point1: List[float]\n",
    "        :param point2: List[float]\n",
    "        :return: float\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @staticmethod\n",
    "    # TODO\n",
    "    def cosine_similarity_distance(point1, point2):\n",
    "        dot = np.dot(point1, point2)\n",
    "        norm1 = np.linalg.norm(point1)\n",
    "        norm2 = np.linalg.norm(point2)\n",
    "        csd = 1 - (dot / (norm1*norm2))\n",
    "        return csd\n",
    "        \"\"\"\n",
    "       :param point1: List[float]\n",
    "       :param point2: List[float]\n",
    "       :return: float\n",
    "       \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @staticmethod\n",
    "    # TODO\n",
    "    def gaussian_kernel_distance(point1, point2):\n",
    "        sub = np.subtract(point1, point2)\n",
    "        dot = np.dot(sub, sub)\n",
    "        gkd = -1*np.exp(dot / (-2))\n",
    "        return gkd\n",
    "        \"\"\"\n",
    "       :param point1: List[float]\n",
    "       :param point2: List[float]\n",
    "       :return: float\n",
    "       \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class HyperparameterTuner:\n",
    "    def __init__(self):\n",
    "        self.best_k = None\n",
    "        self.best_distance_function = None\n",
    "        self.best_scaler = None\n",
    "        self.best_model = None\n",
    "\n",
    "    # TODO: find parameters with the best f1 score on validation dataset\n",
    "    def tuning_without_scaling(self, distance_funcs, x_train, y_train, x_val, y_val):\n",
    "        \"\"\"\n",
    "        In this part, you should try different distance function you implemented in part 1.1, and find the best k.\n",
    "        Use k range from 1 to 30 and increment by 2. Use f1-score to compare different models.\n",
    "\n",
    "        :param distance_funcs: dictionary of distance functions you must use to calculate the distance.\n",
    "            Make sure you loop over all distance functions for each data point and each k value.\n",
    "            You can refer to test.py file to see the format in which these functions will be\n",
    "            passed by the grading script\n",
    "        :param x_train: List[List[int]] training data set to train your KNN model\n",
    "        :param y_train: List[int] train labels to train your KNN model\n",
    "        :param x_val:  List[List[int]] Validation data set will be used on your KNN predict function to produce\n",
    "            predicted labels and tune k and distance function.\n",
    "        :param y_val: List[int] validation labels\n",
    "\n",
    "        Find(tune) best k, distance_function and model (an instance of KNN) and assign to self.best_k,\n",
    "        self.best_distance_function and self.best_model respectively.\n",
    "        NOTE: self.best_scaler will be None\n",
    "\n",
    "        NOTE: When there is a tie, choose model based on the following priorities:\n",
    "        Then check distance function  [canberra > minkowski > euclidean > gaussian > inner_prod > cosine_dist]\n",
    "        If they have same distance fuction, choose model which has a less k.\n",
    "        \"\"\"\n",
    "        \n",
    "        # You need to assign the final values to these variables\n",
    "        self.best_k = None\n",
    "        self.best_distance_function = None\n",
    "        self.best_model = None\n",
    "        \n",
    "        best_f1 = 0\n",
    "        for k in range(1, 30, 2):\n",
    "            for name, function in distance_funcs.items():\n",
    "                model = KNN(k, function)\n",
    "                model.train(x_train, y_train)\n",
    "                prediction = model.predict(x_val)\n",
    "                f1 = f1_score(y_val, prediction)\n",
    "                if (best_f1 < f1):\n",
    "                    best_f1 = f1\n",
    "                    self.best_k = k\n",
    "                    self.best_distance_function = name\n",
    "                    self.best_model = model\n",
    "        return self\n",
    "        \n",
    "        raise NotImplementedError\n",
    "\n",
    "    # TODO: find parameters with the best f1 score on validation dataset, with normalized data\n",
    "    def tuning_with_scaling(self, distance_funcs, scaling_classes, x_train, y_train, x_val, y_val):\n",
    "        \"\"\"\n",
    "        This part is similar to Part 1.3 except that before passing your training and validation data to KNN model to\n",
    "        tune k and disrance function, you need to create the normalized data using these two scalers to transform your\n",
    "        data, both training and validation. Again, we will use f1-score to compare different models.\n",
    "        Here we have 3 hyperparameters i.e. k, distance_function and scaler.\n",
    "\n",
    "        :param distance_funcs: dictionary of distance funtions you use to calculate the distance. Make sure you\n",
    "            loop over all distance function for each data point and each k value.\n",
    "            You can refer to test.py file to see the format in which these functions will be\n",
    "            passed by the grading script\n",
    "        :param scaling_classes: dictionary of scalers you will use to normalized your data.\n",
    "        Refer to test.py file to check the format.\n",
    "        :param x_train: List[List[int]] training data set to train your KNN model\n",
    "        :param y_train: List[int] train labels to train your KNN model\n",
    "        :param x_val: List[List[int]] validation data set you will use on your KNN predict function to produce predicted\n",
    "            labels and tune your k, distance function and scaler.\n",
    "        :param y_val: List[int] validation labels\n",
    "\n",
    "        Find(tune) best k, distance_funtion, scaler and model (an instance of KNN) and assign to self.best_k,\n",
    "        self.best_distance_function, self.best_scaler and self.best_model respectively\n",
    "\n",
    "        NOTE: When there is a tie, choose model based on the following priorities:\n",
    "        For normalization, [min_max_scale > normalize];\n",
    "        Then check distance function  [canberra > minkowski > euclidean > gaussian > inner_prod > cosine_dist]\n",
    "        If they have same distance function, choose model which has a less k.\n",
    "        \"\"\"\n",
    "        \n",
    "        # You need to assign the final values to these variables\n",
    "        self.best_k = None\n",
    "        self.best_distance_function = None\n",
    "        self.best_scaler = None\n",
    "        self.best_model = None\n",
    "        \n",
    "        best_f1 = 0\n",
    "        for k in range(1, 30, 2):\n",
    "            for distance_name, distance_func in distance_funcs.items():\n",
    "                for scaling_name, scaling_class in scaling_classes.items():\n",
    "                    scaler = scaling_class()\n",
    "                    normalized_x_train = scaler(x_train)\n",
    "                    normalized_x_val = scaler(x_val)\n",
    "                    \n",
    "                    model = KNN(k, function)\n",
    "                    model.train(normalized_x_train, y_train)\n",
    "                    prediction = model.predict(normalized_x_val)\n",
    "                    f1 = f1_score(y_val, prediction)\n",
    "                    if (best_f1 < f1):\n",
    "                        best_f1 = f1\n",
    "                        self.best_k = k\n",
    "                        self.best_distance_function = distance_name\n",
    "                        self.best_scaler = scaling_name\n",
    "                        self.best_model = model\n",
    "        return self\n",
    "        \n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class NormalizationScaler:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # TODO: normalize data\n",
    "    def __call__(self, features):\n",
    "        \n",
    "        normalized_features = []\n",
    "        for i in range(len(features)):\n",
    "            denominator = np.sqrt(np.dot(features[i], features[i]))\n",
    "            if (denominator == 0):\n",
    "                normalized = len(features[i]) * [float(0)]\n",
    "                normalized_features.append(normalized)\n",
    "            else:\n",
    "                normalized = (features[i] / denominator).tolist()\n",
    "                normalized_features.append(normalized)\n",
    "        return normalized_features\n",
    "        \"\"\"\n",
    "        Normalize features for every sample\n",
    "\n",
    "        Example\n",
    "        features = [[3, 4], [1, -1], [0, 0]]\n",
    "        return [[0.6, 0.8], [0.707107, -0.707107], [0, 0]]\n",
    "\n",
    "        :param features: List[List[float]]\n",
    "        :return: List[List[float]]\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class MinMaxScaler:\n",
    "    \"\"\"\n",
    "    Please follow this link to know more about min max scaling\n",
    "    https://en.wikipedia.org/wiki/Feature_scaling\n",
    "    You should keep some states inside the object.\n",
    "    You can assume that the parameter of the first __call__\n",
    "    will be the training set.\n",
    "\n",
    "    Hints:\n",
    "        1. Use a variable to check for first __call__ and only compute\n",
    "            and store min/max in that case.\n",
    "\n",
    "    Note:\n",
    "        1. You may assume the parameters are valid when __call__\n",
    "            is being called the first time (you can find min and max).\n",
    "\n",
    "    Example:\n",
    "        train_features = [[0, 10], [2, 0]]\n",
    "        test_features = [[20, 1]]\n",
    "\n",
    "        scaler1 = MinMaxScale()\n",
    "        train_features_scaled = scaler1(train_features)\n",
    "        # train_features_scaled should be equal to [[0, 1], [1, 0]]\n",
    "\n",
    "        test_features_scaled = scaler1(test_features)\n",
    "        # test_features_scaled should be equal to [[10, 0.1]]\n",
    "\n",
    "        new_scaler = MinMaxScale() # creating a new scaler\n",
    "        _ = new_scaler([[1, 1], [0, 0]]) # new trainfeatures\n",
    "        test_features_scaled = new_scaler(test_features)\n",
    "        # now test_features_scaled should be [[20, 1]]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.first_call = True\n",
    "        self.max = []\n",
    "        self.min = []\n",
    "        pass\n",
    "\n",
    "    def __call__(self, features):\n",
    "        if (self.first_call = True):\n",
    "            self.first_call = False\n",
    "            self.max = np.max(features, axis = 0)\n",
    "            self.min = np.min(features, axis = 0)\n",
    "            \n",
    "        difference = self.max - self.min\n",
    "        \n",
    "        normalized_features = []\n",
    "        for i in range(len(features)):\n",
    "            normalized_feature = np.divide(np.subtract(features[i], self.min), difference, dtype=float)\n",
    "            normalized_features.append(normalized_feature)\n",
    "            \n",
    "        return normalized_features\n",
    "        \"\"\"\n",
    "        normalize the feature vector for each sample . For example,\n",
    "        if the input features = [[2, -1], [-1, 5], [0, 0]],\n",
    "        the output should be [[1, 0], [0, 1], [0.333333, 0.16667]]\n",
    "\n",
    "        :param features: List[List[float]]\n",
    "        :return: List[List[float]]\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k, distance_function):\n",
    "        \"\"\"\n",
    "        :param k: int\n",
    "        :param distance_function\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.distance_function = distance_function\n",
    "\n",
    "    # TODO: save features and lable to self\n",
    "    def train(self, features, labels):\n",
    "        self.train_features = features\n",
    "        self.train_labels = labels\n",
    "        \"\"\"\n",
    "        In this function, features is simply training data which is a 2D list with float values.\n",
    "        For example, if the data looks like the following: Student 1 with features age 25, grade 3.8 and labeled as 0,\n",
    "        Student 2 with features age 22, grade 3.0 and labeled as 1, then the feature data would be\n",
    "        [ [25.0, 3.8], [22.0,3.0] ] and the corresponding label would be [0,1]\n",
    "\n",
    "        For KNN, the training process is just loading of training data. Thus, all you need to do in this function\n",
    "        is create some local variable in KNN class to store this data so you can use the data in later process.\n",
    "        :param features: List[List[float]]\n",
    "        :param labels: List[int]\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # TODO: predict labels of a list of points\n",
    "    def predict(self, features):\n",
    "        \n",
    "        predicted_labels = []\n",
    "        for i in features:\n",
    "            predicted_label = Counter(self.get_k_neighbors(i)).most_common()[0][0]\n",
    "            predicted_labels.append(predicted_label)\n",
    "            \n",
    "        return predicted_labels\n",
    "        \"\"\"\n",
    "        This function takes 2D list of test data points, similar to those from train function. Here, you need process\n",
    "        every test data point, reuse the get_k_neighbours function to find the nearest k neighbours for each test\n",
    "        data point, find the majority of labels for these neighbours as the predict label for that testing data point.\n",
    "        Thus, you will get N predicted label for N test data point.\n",
    "        This function need to return a list of predicted labels for all test data points.\n",
    "        :param features: List[List[float]]\n",
    "        :return: List[int]\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # TODO: find KNN of one point\n",
    "    def get_k_neighbors(self, point):\n",
    "        \n",
    "        distances = []\n",
    "        for i in range(len(self.train_features)):\n",
    "            distance = self.distance_function(self.train_features[i], point)\n",
    "            distances.append(distance)\n",
    "            sorted_all_neighbors = np.argsort(distances)\n",
    "            k_neighbors = sorted_all_neighbors[0 : self.k]\n",
    "            \n",
    "            k_neighbors_list = []\n",
    "            for i in k_neighbors:\n",
    "                k_neighbors_list.append(self.train_labels[i])\n",
    "                \n",
    "            return k_neighbors_list\n",
    "        \"\"\"\n",
    "        This function takes one single data point and finds k-nearest neighbours in the training set.\n",
    "        You already have your k value, distance function and you just stored all training data in KNN class with the\n",
    "        train function. This function needs to return a list of labels of all k neighours.\n",
    "        :param point: List[float]\n",
    "        :return:  List[int]\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(np.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jam/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.divide(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.62623999999998"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(2.4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0,9,0,2,3,5]\n",
    "a[a==0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 9, 0, 2, 3, 5]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 9, 0, 2, 3, 5])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 9, 0, 2, 3, 5]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[a==0] = 1\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "point1 = [1,3,2,0,5]\n",
    "point2 = [2,3,4,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "denominator = np.abs(np.asarray(point1))+np.abs(np.asarray(point2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 6, 6, 0, 6])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(denominator.shape[0]):\n",
    "    if (denominator[i] == 0):\n",
    "        denominator[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 6, 6, 1, 6])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0]*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=[[1,2],[3,4],[0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "if ([0] == [0,0]):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [2,3,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.max(b, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.min(b, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d-e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(d-e)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 0])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.divide(np.subtract(features[0], min[0]), difference[0], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features=[]\n",
    "normalized_features.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.33333333, 0.66666667]), array([0.33333333, 0.66666667])]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-cebb9debb809>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mnormalized_feature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 \u001b[0mnormalized_feature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdifference\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mnormalized_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_feature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "normalized_features=[]\n",
    "for i in range(len(features)):\n",
    "            if (difference[0] == 0):\n",
    "                normalized_feature[i] = [0]*len(features[i])\n",
    "            else:\n",
    "                normalized_feature[i] = np.divide(np.subtract(features[i], min[i]), difference[i], dtype=float)\n",
    "            \n",
    "            normalized_features.append(normalized_feature[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 3)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(features)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features = []\n",
    "for i in range(len(features)):\n",
    "    normalized_feature = np.divide(np.subtract(features[i], min), difference, dtype=float)\n",
    "    normalized_features.append(normalized_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.33333333, 0.5       ]), array([1., 1.]), array([0., 0.])]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [3,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "min = []\n",
    "max = []\n",
    "for d in range(0,len(features[0])): \n",
    "    sFeatures = sorted(features, key=lambda x: x[d])\n",
    "                # Get min\n",
    "    min.append(sFeatures[0][d])\n",
    "                # Get max \n",
    "    max.append(sFeatures[len(features)-1][d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 7])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [[1,2],[3,4],[0,0],[4,7]]\n",
    "max = np.max(features, axis=0)\n",
    "min= np.min(features, axis=0)\n",
    "difference = max-min\n",
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features=[]\n",
    "for i in range(len(features)):\n",
    "    nf = []\n",
    "    for j in range(len(features[i])):\n",
    "        if (difference[j] == 0):\n",
    "            nf.append(0)\n",
    "        else:\n",
    "            nf.append(np.divide(np.subtract(features[i][j], min[j]), difference[j], dtype=float))\n",
    "            \n",
    "    normalized_features.append(nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.25, 0.2857142857142857],\n",
       " [0.75, 0.5714285714285714],\n",
       " [0.0, 0.0],\n",
       " [1.0, 1.0]]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(features)):\n",
    "            nf = []\n",
    "            for j in range(len(features[i])):\n",
    "                if (difference[j] == 0):\n",
    "                    nf.append(0)\n",
    "                else:\n",
    "                    nf.append(np.divide(np.subtract(\n",
    "                        features[i][j], self.min[j]), difference[j], dtype=float))\n",
    "\n",
    "                normalized_features.append(nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=list()\n",
    "for i in range(len(features)):\n",
    "            temp=[]\n",
    "            for j in range(len(features[0])):\n",
    "                if(diff[j]==0):\n",
    "                   # print('diff is zero')\n",
    "                    temp.append(0)\n",
    "                else:\n",
    "                    div=(features[i][j]-self.min_a[j])/diff[j]\n",
    "                    temp.append(div)\n",
    "            result.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter([0,0,0,1,1,0]).most_common()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 4, 1: 2})"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([0,0,0,1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
